{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c71057e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.11/site-packages (0.2.0)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.11/site-packages (0.1.1)\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.11/site-packages (from sacremoses) (2024.7.24)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.11/site-packages (from sacremoses) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.11/site-packages (from sacremoses) (1.3.2)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from sacremoses) (4.66.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece sacremoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f75611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-de-en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "330c2f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# DE-EN\n",
    "de_tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-de-en\")\n",
    "de_model = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-de-en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44754d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2b1f04782634c279828c6284b6fc658",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/298M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb0bdbb2f19f4d35b0e8d90380a1fa2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# EN-DE\n",
    "en_tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-de\")\n",
    "en_model = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-en-de\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57b1d845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate Deutsch-to-English\n",
    "\n",
    "\n",
    "def translate_de_en(de_txt):\n",
    "    # Tokenize the input text\n",
    "    input_tokens = de_tokenizer.encode(de_txt, return_tensors=\"pt\")\n",
    "\n",
    "    # Generate translation\n",
    "    translation_tokens = de_model.generate(input_tokens)\n",
    "\n",
    "    # Decode the output tokens into a human-readable string\n",
    "    translated_text = de_tokenizer.decode(translation_tokens[0], skip_special_tokens=True)\n",
    "\n",
    "    # Print the translated sentence\n",
    "    print(translated_text)\n",
    "    \n",
    "    \n",
    "# Translate English to Deutsch\n",
    "\n",
    "\n",
    "def translate_en_de(en_txt):\n",
    "    # Tokenize the input text\n",
    "    input_tokens = en_tokenizer.encode(en_txt, return_tensors=\"pt\")\n",
    "\n",
    "    # Generate translation\n",
    "    translation_tokens = en_model.generate(input_tokens)\n",
    "\n",
    "    # Decode the output tokens into a human-readable string\n",
    "    translated_text = en_tokenizer.decode(translation_tokens[0], skip_special_tokens=True)\n",
    "\n",
    "    # Print the translated sentence\n",
    "    print(translated_text)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed65b246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input sentence in German\n",
    "german_text = \"Ich muss unseren Termin am 19. April absagen. Ich fliege an dem Tag von Seattle zurück und bin nicht rechtzeitig zurück. Tut mir leid. Wenn du am Sonntag, den 20. April, Zeit hast, könnte ich dich gegen 16:30 Uhr treffen. Aber ich weiß, es ist Ostersonntag, also keine Sorge.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f8b7210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have to cancel our appointment on April 19th. I'm going back from Seattle that day and I'm not back in time. I'm sorry. If you have time on Sunday, April 20th, I could meet you around 4:30 p.m. But I know it's Easter Sunday, so don't worry.\n"
     ]
    }
   ],
   "source": [
    "translate_de_en(german_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62f4213e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input sentence in English\n",
    "english_text = \"Hi, sounds like a good trip! Thanks for letting me know. I think I am okay with canceling lessons April 19-20.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0da9658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hallo, klingt wie eine gute Reise! Danke, dass Sie mich wissen lassen. Ich denke, ich bin okay mit Absagen Lektionen April 19-20.\n"
     ]
    }
   ],
   "source": [
    "translate_en_de(english_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "25345287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who in your family has pets?\n"
     ]
    }
   ],
   "source": [
    "translate_de_en(\"Wer in deiner Familie hat Haustiere? Wie heißen sie? \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73506402",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
